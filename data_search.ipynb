{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dotenv.load_dotenv()"
   ],
   "id": "6c5acacbe1107959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('data/Final_TestSet/Final_TestSet.json', 'r', encoding='utf-8') as f:\n",
    "    dataset_init=json.load(f)\n",
    "with open('data/Final_Example.json', 'r', encoding='utf-8') as f:\n",
    "    preliminary_example=json.load(f)\n",
    "\n",
    "for i in range(0, len(dataset_init)):\n",
    "    # 检查数据集文件是否一致\n",
    "    assert dataset_init[i][\"ID\"] == preliminary_example[i][\"ID\"] \n",
    "    assert dataset_init[i][\"question\"] == preliminary_example[i][\"question\"]\n",
    "    \n",
    "print(\"样本数量：\",len(dataset_init))\n",
    "# print(\"问题类型：\",\",\".join(set([item[\"problem_type\"] for item in dataset_init])))\n",
    "\n",
    "\n",
    "FROM=0\n",
    "TO=FROM+512\n",
    "dataset=dataset_init[FROM:TO]"
   ],
   "id": "84069d40e467c4fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gpt4o=ChatOpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "gpt4o.invoke(\"hello\")\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\")) # "
   ],
   "id": "55286c5707b8d594"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 预处理\n",
    "### 1. 翻译"
   ],
   "id": "5f52202fb492f5ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tool.langchain_tool import translate_prompt\n",
    "\n",
    "# 翻译所有问题，已经缓存，所以全量翻译\n",
    "translation_runnable= translate_prompt | gpt4o | StrOutputParser()\n",
    "translation_list = translation_runnable.batch([{\"text\":item[\"question\"]} for item in dataset], config={\"max_concurrency\":1}, return_exceptions=True)\n",
    "for i in range(0,len(dataset)):\n",
    "    dataset[i][\"translation\"]=translation_list[i]"
   ],
   "id": "b87776698233b00e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. 抽取题目中的函数和类",
   "id": "89235d24201dbd3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tool.langchain_tool import extract_runnable\n",
    "\n",
    "# 从翻译中提取出函数和库，重复多次，保证成功\n",
    "tmp_extract_dict={}\n",
    "for i in tqdm(range(5)):\n",
    "    tmp_extract_dict[i]=tmp_extract_list=extract_runnable.batch([{\"text\":str(i)+\"\\n\"+item[\"translation\"]} for item in dataset[:]], config={\"max_concurrency\":5}, return_exceptions=True)\n",
    "\n",
    "for i in range(1,len(tmp_extract_dict)):\n",
    "    for j in range(len(tmp_extract_dict[i])):\n",
    "        tmp_extract_dict[0][j].extend(tmp_extract_dict[i][j])\n",
    "\n",
    "def remove_duplicates(lst):\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for d in lst:\n",
    "        # 将字典转换为字符串，这样就可以用作字典的键\n",
    "        dict_str = str(d) #d[\"function_name\"]\n",
    "        if dict_str not in seen:\n",
    "            seen[dict_str] = True\n",
    "            result.append(d)\n",
    "    return result\n",
    "extract_list=[]\n",
    "for item in tmp_extract_dict[0]:\n",
    "    extract_list.append(remove_duplicates(item))\n",
    "\n",
    "for i in range(len(extract_list)):\n",
    "    # print(i+1,extract_list[i])\n",
    "    dataset[i][\"func_extract\"]=extract_list[i]\n",
    "\n",
    "# extract_list=extract_runnable.batch([{\"text\":item[\"translation\"]} for item in dataset[:]], config={\"max_concurrency\":5}, return_exceptions=True)\n",
    "# for i in range(len(extract_list)):\n",
    "#     # print(i+1,extract_list[i])\n",
    "#     dataset[i][\"func_extract\"]=extract_list[i]"
   ],
   "id": "71a5a82339f5bc1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. 根据搜索到的类型和搜索到的文档，搜索出对应的函数文档",
   "id": "759e9e9ad618b096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tool.rag_tool import search_documents_by_help_function\n",
    "\n",
    "for i,key_work in tqdm(enumerate(extract_list), total=len(extract_list)):\n",
    "    key_work=key_work if type(key_work) is list else [key_work]\n",
    "    tmp_set=set()\n",
    "    for kw in key_work:\n",
    "        # print(kw)\n",
    "        doc=search_documents_by_help_function(\n",
    "            kw[\"function_name\"].split(\".\")[-1],\n",
    "            kw[\"module_name\"].lower().strip().split(\".\")[0]\n",
    "        )\n",
    "        tmp_set.add(\"<api doc>\\n\" + doc + \"\\n</api doc>\")\n",
    "    dataset[i][\"rag_infos\"]=tmp_set"
   ],
   "id": "53550bd1edaf9a8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. 根据题目，搜索向量数据库的相关函数/类，然后获取相关函数/类的文档 ",
   "id": "27d535bb5d996dc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from tool.rag_tool import search_documents_in_mutil_keywords\n",
    "\n",
    "for item in tqdm(dataset[:]):\n",
    "    question=item[\"question\"]\n",
    "    tmp_l=[]\n",
    "    for doc_json,_,_ in search_documents_in_mutil_keywords([], question,10):\n",
    "        function_name=\"\"\n",
    "        for key in doc_json:\n",
    "            if str(key).startswith(\"Field List > Methods > \"):\n",
    "                function_name=key[22:].strip()\n",
    "        if function_name!=\"\":\n",
    "            class_name=doc_json[\"Section_id\"] if \"Section_id\" in doc_json else doc_json[\"Section ID\"]\n",
    "        else:\n",
    "            function_name=doc_json[\"Section_id\"] if \"Section_id\" in doc_json else doc_json[\"Section ID\"]\n",
    "            class_name=\"\"\n",
    "        package_name=doc_json[\"module\"]\n",
    "        \n",
    "        help_doc=search_documents_by_help_function(function_name,package_name,contain_key=class_name)\n",
    "        if len(help_doc)>15000:\n",
    "            init_len=len(help_doc)\n",
    "            help_doc=(gpt4o|StrOutputParser()).invoke(f\"Below is the documentation generated by the help() function. Extract the main information and reduce the word count to 500 words\\n{help_doc}\")\n",
    "            after_len=len(help_doc)\n",
    "            print(f\"{package_name}.{function_name} {init_len} -> {after_len}\")\n",
    "        tmp_l.append(f\"function:{function_name}, class:{class_name}, package:{package_name}, doc:'{repr(help_doc)[1:-1] }'\")\n",
    "    item[\"func_bk\"]=tmp_l\n",
    "    "
   ],
   "id": "7110f7c11bcb6723"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. 构建把所有信息构建prompt",
   "id": "3441b2e68a869dd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tool.autogen_tool import *\n",
    "for i in range(0, len(dataset)):\n",
    "    # 顺序 rag的函数文档-抽取的函数文档-题目\n",
    "    content=\"\"\n",
    "    \n",
    "    content += \"\\n\\nThe following functions can be used optionally:\\n\"+\"\\n\".join(dataset[i][\"func_bk\"])\n",
    "    \n",
    "    content += \"\\n\\nThe following function must be used:\\n\"+\"\\n\".join(dataset[i][\"rag_infos\"])\n",
    "    \n",
    "    question = d_template[dataset[i][\"problem_type\"]].format(dataset[i][\"question\"])\n",
    "    # filenames = extract_filenames(question)\n",
    "    # for filename in filenames:\n",
    "    #     question = question.replace(filename, add_path(filename, data_path / 'Final_TestSet/data'))\n",
    "    content += \"\\n\\n\\n\"+question+\"\\n\\n\"\n",
    "\n",
    "    dataset[i][\"content\"]=content\n"
   ],
   "id": "9665fab531bebd44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 添加目标\n",
    "对于mutil类，这里给这种类型添加额外的目标说明，保证其输出"
   ],
   "id": "16b41a57ec21c910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "from tool.langchain_tool import cal_prompt, draw_prompt, tof_prompt\n",
    "\n",
    "def get_goals(text:str, problem_type:str):\n",
    "    types=[]\n",
    "    goals=[]\n",
    "    if problem_type.startswith(\"multi\"):\n",
    "        types.extend(problem_type[6:-1].split(\", \"))\n",
    "    else:\n",
    "        types.append(problem_type)\n",
    "\n",
    "    for t in types:\n",
    "        if t==\"calculations\":\n",
    "            prompt=cal_prompt\n",
    "        elif t==\"True/False\":\n",
    "            prompt=tof_prompt\n",
    "        elif t==\"draw\":\n",
    "            prompt=draw_prompt\n",
    "        else:\n",
    "            raise Exception(\"unknown problem type\")\n",
    "    \n",
    "        runnable=prompt|gpt4o|StrOutputParser()\n",
    "        goal=runnable.invoke({\"question\":text})\n",
    "        goals.append(goal)\n",
    "    return goals\n",
    "        \n",
    "        \n",
    "for i in tqdm(range(len(dataset))):\n",
    "    if dataset[i][\"problem_type\"].startswith(\"multi\"):\n",
    "        goals=get_goals(dataset[i][\"question\"], dataset[i][\"problem_type\"])\n",
    "        # print(i+1,goals)\n",
    "        dataset[i][\"goals\"]=goals\n",
    "        dataset[i][\"content\"]=dataset[i][\"content\"]+\"\\n\\n\"+\"\\nwe need to answer following question：\\n\"+\"\\n\".join(goals)\n",
    "    "
   ],
   "id": "73d0f46a0107d17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "id_and_content=[{\"ID\":i[\"ID\"], \"content\":i[\"content\"]} for i in dataset]\n",
    "with open('data/id_and_content.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(id_and_content, f)"
   ],
   "id": "3bcd8335be3a3d5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "raise Exception(\"stop\")",
   "id": "135b4b00091795fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "## 以下为测试代码"
   ],
   "id": "a720e8d6f6829d97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 运行\n",
    "### 运行agent"
   ],
   "id": "1aa5787a1e6b2bf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from autogen import Cache\n",
    "\n",
    "from tool.autogen_tool import *\n",
    "\n",
    "def run(item: dict,cache_seed=1):\n",
    "    content = item[\"content\"]\n",
    "    item[\"content\"]=content\n",
    "\n",
    "    # Use DiskCache as cache\n",
    "    with Cache.disk(cache_path_root=\"./autogen_cache\",cache_seed=cache_seed) as cache:\n",
    "        chat_result = code_executor_agent.initiate_chat(\n",
    "            code_writer_agent,\n",
    "            message=content,\n",
    "            summary_method='reflection_with_llm',\n",
    "            summary_args=dict(summary_prompt='only return the code output, if no output just return \"done!\"'),\n",
    "            cache=cache,\n",
    "            # silent=True,\n",
    "        )\n",
    "    # code = extract_python_code(chat_result.chat_history[-3]['content'])[-1]\n",
    "    code=\"\"\n",
    "    for i in range(len(chat_result.chat_history)-1, 0, -1):\n",
    "        l=extract_python_code(chat_result.chat_history[i]['content'])\n",
    "        if len(l)>0:\n",
    "            code=l[-1]\n",
    "            break\n",
    "    \n",
    "    answer = chat_result.summary\n",
    "    if isinstance(answer, dict):\n",
    "        answer = answer['content']\n",
    "    item[\"code\"]=code\n",
    "    item[\"answer\"]=answer\n",
    "    # item['chat_history']=chat_result.chat_history\n",
    "    return item\n",
    "\n",
    "\n",
    "for item in tqdm(dataset[487:488]):\n",
    "    run(item)\n"
   ],
   "id": "e65cbc2f583d3d75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "358e20729af3f21b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 存储",
   "id": "6e385dd31a767b31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in dataset:\n",
    "    if type(i['rag_infos']) is set:\n",
    "        i['rag_infos']=list(i['rag_infos'])"
   ],
   "id": "b5fd98e775cd83d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('data/SMP_240917_check_1.json', 'w', encoding='utf-8') as f:\n",
    "    s = json.dumps(dataset, indent=4, ensure_ascii=False)\n",
    "    f.write(s)"
   ],
   "id": "baccd2846d1d777f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
