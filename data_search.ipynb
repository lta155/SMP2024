{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:08:20.111012Z",
     "start_time": "2024-09-06T08:08:17.479821Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dotenv.load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T09:45:33.895078Z",
     "start_time": "2024-09-06T09:45:33.873023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('res/Final_TestSet/Final_TestSet.json', 'r', encoding='utf-8') as f:\n",
    "    dataset_init=json.load(f)\n",
    "with open('res/Final_Example.json', 'r', encoding='utf-8') as f:\n",
    "    preliminary_example=json.load(f)\n",
    "\n",
    "for i in range(0, len(dataset_init)):\n",
    "    # 检查数据集文件是否一致\n",
    "    assert dataset_init[i][\"ID\"] == preliminary_example[i][\"ID\"] \n",
    "    assert dataset_init[i][\"question\"] == preliminary_example[i][\"question\"]\n",
    "    \n",
    "print(\"样本数量：\",len(dataset_init))\n",
    "print(\"问题类型：\",\",\".join(set([item[\"problem_type\"] for item in dataset_init])))\n",
    "# 结算每种问题类型的比率\n",
    "problem_type_counts = {problem_type: 0 for problem_type in set([item[\"problem_type\"] for item in dataset_init])}\n",
    "for i in range(0, len(dataset_init)):\n",
    "    problem_type_counts[dataset_init[i][\"problem_type\"]] += 1\n",
    "# 显示比率, 排序，每行\n",
    "for problem_type, count in sorted(problem_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{problem_type}: {count / len(dataset_init):.2%}\")\n",
    "\n",
    "FROM=0\n",
    "TO=FROM+512\n",
    "dataset=dataset_init[FROM:TO]"
   ],
   "id": "ffdd5e309a334511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量： 512\n",
      "问题类型： multi(draw, True/False),multi(calculations, True/False),True/False,calculations,multi(True/False, draw),multi(True/False, calculations),multi(calculations, draw),draw\n",
      "calculations: 75.20%\n",
      "multi(True/False, calculations): 8.40%\n",
      "True/False: 7.62%\n",
      "draw: 6.25%\n",
      "multi(True/False, draw): 0.98%\n",
      "multi(calculations, draw): 0.98%\n",
      "multi(calculations, True/False): 0.39%\n",
      "multi(draw, True/False): 0.20%\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:12:23.841322Z",
     "start_time": "2024-09-06T06:12:23.220941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpt4o=ChatOpenAI(\n",
    "    api_key=os.getenv(\"WLAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"WLAI_BASE_URL\"),\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "gpt4o.invoke(\"hello\")\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\")) # "
   ],
   "id": "ed9aa0c611d6cdc2",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 翻译",
   "id": "574afcb7b791980c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:12:27.094441Z",
     "start_time": "2024-09-06T06:12:23.873321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tool.model import translate_prompt\n",
    "\n",
    "# 翻译所有问题，已经缓存，所以全量翻译\n",
    "translation_runnable= translate_prompt | gpt4o | StrOutputParser()\n",
    "translation_list = translation_runnable.batch([{\"text\":item[\"question\"]} for item in dataset], config={\"max_concurrency\":1}, return_exceptions=True)\n",
    "for i in range(0,len(dataset)):\n",
    "    dataset[i][\"translation\"]=translation_list[i]"
   ],
   "id": "645074f81eea53b7",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 运行\n",
    "### 预处理\n",
    "1. 构建prompt\n",
    "2. 修改题目中文件名位置"
   ],
   "id": "785a6b9588f98da5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:12:27.189094Z",
     "start_time": "2024-09-06T06:12:27.135083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt4o import *\n",
    "for i in range(0, len(dataset)):\n",
    "    content = d_template[dataset[i][\"problem_type\"]].format(dataset[i][\"question\"])\n",
    "    filenames = extract_filenames(content)\n",
    "    for filename in filenames:\n",
    "        content = content.replace(filename, add_path(filename, data_path / 'Final_TestSet/data'))\n",
    "    dataset[i][\"content\"]=content"
   ],
   "id": "60042329e696a5cf",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 运行agent",
   "id": "a0ca324b051de187"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from autogen import Cache\n",
    "\n",
    "def run(item: dict):\n",
    "    content = item[\"content\"]\n",
    "\n",
    "    # Use DiskCache as cache\n",
    "    with Cache.disk(cache_path_root=\"./autogen_cache\",cache_seed=1) as cache:\n",
    "        chat_result = code_executor_agent.initiate_chat(\n",
    "            code_writer_agent,\n",
    "            message=content,\n",
    "            summary_method='reflection_with_llm',\n",
    "            summary_args=dict(summary_prompt='only return the code output'),\n",
    "            cache=cache,\n",
    "            # silent=True,\n",
    "        )\n",
    "    # code = extract_python_code(chat_result.chat_history[-3]['content'])[-1]\n",
    "    code=\"\"\n",
    "    for i in range(len(chat_result.chat_history)-1, 0, -1):\n",
    "        l=extract_python_code(chat_result.chat_history[i]['content'])\n",
    "        if len(l)>0:\n",
    "            code=l[-1]\n",
    "            break\n",
    "    \n",
    "    answer = chat_result.summary\n",
    "    if isinstance(answer, dict):\n",
    "        answer = answer['content']\n",
    "    item[\"code\"]=code\n",
    "    item[\"answer\"]=answer\n",
    "    item['chat_history']=chat_result.chat_history\n",
    "    return item\n",
    "\n",
    "for item in tqdm(dataset[:100]):\n",
    "    run(item)\n"
   ],
   "id": "372043cc6b22dc2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 存储",
   "id": "573bc4288f92333d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T06:12:51.861296600Z",
     "start_time": "2024-09-05T13:35:37.313620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('res/SMP_240905_check_1.json', 'w', encoding='utf-8') as f:\n",
    "    s = json.dumps(dataset, indent=4, ensure_ascii=False)\n",
    "    f.write(s)"
   ],
   "id": "99d59b27c6efe78",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "----",
   "id": "28657a61d400979b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "raise Exception(\"stop\")",
   "id": "4f8860b7e6239bd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T08:08:22.362637Z",
     "start_time": "2024-09-06T08:08:22.316638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('res/SMP_240905_check_1.json', 'r', encoding='utf-8') as f:\n",
    "    tmp_dataset=json.load(f)"
   ],
   "id": "5148f3e17df16072",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tmp_id=50\n",
    "i=tmp_id-1\n",
    "print(tmp_dataset[i][\"ID\"], tmp_dataset[i][\"problem_type\"],\"\\n---\\n\", tmp_dataset[i][\"translation\"],\"\\n---\\n\", tmp_dataset[i]['answer'],\"\\n---\\n\",tmp_dataset[i][\"code\"],\"\\n---\\n\",tmp_dataset[i][\"question\"])"
   ],
   "id": "5dc053e492298f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T01:17:48.038080Z",
     "start_time": "2024-09-07T01:17:48.026106Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # filename: coffee_roasting_workflow.py\n",
    "import networkx as nx\n",
    "\n",
    "# Step 1: Create the graph\n",
    "G = nx.DiGraph()\n",
    "nodes = [(1, {'group': 0}), (2, {'group': 1}), (3, {'group': 1}), (4, {'group': 1})]\n",
    "edges = [(1, 2), (2, 3)]\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Step 2: Define sets S and T\n",
    "S = {1, 2}\n",
    "T = {3, 4}\n",
    "\n",
    "# Step 3: Calculate the mixing expansion\n",
    "def mixing_expansion(G, S, T):\n",
    "    # Count the number of edges from S to T\n",
    "    edges_from_S_to_T = sum(1 for u, v in G.edges() if u in S and v in T)\n",
    "    # Calculate the size of the sets\n",
    "    size_S = len(S)\n",
    "    size_T = len(T)\n",
    "    # Mixing expansion formula\n",
    "    if size_S == 0 or size_T == 0:\n",
    "        return 0\n",
    "    return edges_from_S_to_T / (size_S * size_T)\n",
    "\n",
    "mixing_expansion_value = nx.mixing_expansion(G, S, T)\n",
    "print(f\"{mixing_expansion_value:.2f}\") "
   ],
   "id": "fd58ce7c7e786467",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "885b6e5a43a1861c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:01:18.304182Z",
     "start_time": "2024-09-06T15:01:18.162377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from community import community_louvain  # Louvain is close to Leiden, used as a proxy\n",
    "from sklearn.metrics import f1_score\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "\n",
    "# Step 1: 加载足球图形数据\n",
    "G = nx.read_gml('res/Final_TestSet/data/football.gml')\n",
    "\n",
    "# 获取 networkx 图中的节点名称\n",
    "nx_nodes = list(G.nodes())\n",
    "\n",
    "# Step 2: 使用 greedy_modularity_communities 进行社区检测\n",
    "greedy_communities = list(greedy_modularity_communities(G))\n",
    "\n",
    "# 将每个节点的社区分配记录下来\n",
    "greedy_labels = {node: i for i, community in enumerate(greedy_communities) for node in community}\n",
    "\n",
    "# Step 3: 使用 Louvain 作为 Leiden 的参考\n",
    "partition = community_louvain.best_partition(G)\n",
    "louvain_labels = [partition[node] for node in G.nodes()]\n",
    "\n",
    "# Step 4: 转换成 igraph 图，并使用 Leiden 算法\n",
    "# 使用元组列表构建 igraph 图，同时保留原始节点标签\n",
    "ig_graph = ig.Graph.TupleList([(nx_nodes.index(u), nx_nodes.index(v)) for u, v in G.edges()], directed=False)\n",
    "\n",
    "# 使用 Leiden 算法进行社区检测\n",
    "leiden_community = la.find_partition(ig_graph, la.ModularityVertexPartition)\n",
    "\n",
    "# 创建一个字典来存储 igraph 索引和其相应的 community id\n",
    "leiden_labels = {nx_nodes[node]: i for i, community in enumerate(leiden_community) for node in community}\n",
    "\n",
    "# Step 5: 比较 Greedy 和 Leiden 输出，计算 F1 得分\n",
    "greedy_labels_list = [greedy_labels[node] for node in nx_nodes]\n",
    "leiden_labels_list = [leiden_labels[node] for node in nx_nodes]\n",
    "\n",
    "# 计算 F1 得分\n",
    "f1 = f1_score(greedy_labels_list, leiden_labels_list, average='macro')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Average F1 score between Greedy Modularity and Leiden method: \", f1)\n"
   ],
   "id": "bb1122b42b237704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score between Greedy Modularity and Leiden method:  0.12302414889436646\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T15:17:49.054555Z",
     "start_time": "2024-09-06T15:17:48.900933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "from sklearn.metrics import f1_score\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from community import community_louvain\n",
    "from igraph import Graph\n",
    "\n",
    "# Step 1: 加载足球图形数据\n",
    "G = nx.read_gml('res/Final_TestSet/data/football.gml')\n",
    "\n",
    "# 获取 networkx 图中的节点名称\n",
    "nx_nodes = list(G.nodes())\n",
    "\n",
    "# Step 2: 使用 greedy_modularity_communities 进行社区检测\n",
    "greedy_communities = list(greedy_modularity_communities(G))\n",
    "greedy_labels = {node: i for i, community in enumerate(greedy_communities) for node in community}\n",
    "\n",
    "# Step 3: 使用 Louvain 作为 Leiden 的参考\n",
    "partition = community_louvain.best_partition(G)\n",
    "louvain_labels = [partition[node] for node in G.nodes()]\n",
    "\n",
    "# Step 4: 转换成 igraph 图，并使用 Leiden 算法\n",
    "ig_graph = ig.Graph.TupleList([(nx_nodes.index(u), nx_nodes.index(v)) for u, v in G.edges()], directed=False)\n",
    "\n",
    "# 使用 Leiden 算法进行社区检测，使用 modularity 作为目标函数\n",
    "leiden_community = Graph.community_leiden(ig_graph)\n",
    "\n",
    "# 创建一个字典来存储 igraph 索引和其相应的 community id\n",
    "leiden_labels = {nx_nodes[node]: i for i, community in enumerate(leiden_community) for node in community}\n",
    "\n",
    "# Step 5: 比较 Greedy 和 Leiden 输出，计算 F1 得分\n",
    "greedy_labels_list = [greedy_labels[node] for node in nx_nodes]\n",
    "leiden_labels_list = [leiden_labels[node] for node in nx_nodes]\n",
    "\n",
    "# 计算 F1 得分\n",
    "f1 = f1_score(greedy_labels_list, leiden_labels_list, average='macro')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Average F1 score between Greedy Modularity and Leiden method: \", f1)\n"
   ],
   "id": "c7d3742690351f3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score between Greedy Modularity and Leiden method:  0.0007905138339920949\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(50):\n",
    "    print(tmp_dataset[i]['problem_type'])"
   ],
   "id": "6b3a7811fde3474e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 绘制graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw(G, with_labels=True, node_size=1000, node_color='skyblue', font_size=36)\n",
    "plt.show()"
   ],
   "id": "39102f140c1db8b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
