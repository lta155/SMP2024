{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:17.499649Z",
     "start_time": "2024-09-07T13:03:17.476322Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dotenv.load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:18.935227Z",
     "start_time": "2024-09-07T13:03:18.910865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('data/Final_TestSet/Final_TestSet.json', 'r', encoding='utf-8') as f:\n",
    "    dataset_init=json.load(f)\n",
    "with open('data/Final_Example.json', 'r', encoding='utf-8') as f:\n",
    "    preliminary_example=json.load(f)\n",
    "\n",
    "for i in range(0, len(dataset_init)):\n",
    "    # 检查数据集文件是否一致\n",
    "    assert dataset_init[i][\"ID\"] == preliminary_example[i][\"ID\"] \n",
    "    assert dataset_init[i][\"question\"] == preliminary_example[i][\"question\"]\n",
    "    \n",
    "print(\"样本数量：\",len(dataset_init))\n",
    "print(\"问题类型：\",\",\".join(set([item[\"problem_type\"] for item in dataset_init])))\n",
    "# 结算每种问题类型的比率\n",
    "problem_type_counts = {problem_type: 0 for problem_type in set([item[\"problem_type\"] for item in dataset_init])}\n",
    "for i in range(0, len(dataset_init)):\n",
    "    problem_type_counts[dataset_init[i][\"problem_type\"]] += 1\n",
    "# 显示比率, 排序，每行\n",
    "for problem_type, count in sorted(problem_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{problem_type}: {count / len(dataset_init):.2%}\")\n",
    "\n",
    "FROM=0\n",
    "TO=FROM+50\n",
    "dataset=dataset_init[FROM:TO]"
   ],
   "id": "ffdd5e309a334511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量： 512\n",
      "问题类型： multi(True/False, calculations),multi(calculations, True/False),multi(True/False, draw),multi(draw, True/False),multi(calculations, draw),True/False,draw,calculations\n",
      "calculations: 75.20%\n",
      "multi(True/False, calculations): 8.40%\n",
      "True/False: 7.62%\n",
      "draw: 6.25%\n",
      "multi(True/False, draw): 0.98%\n",
      "multi(calculations, draw): 0.98%\n",
      "multi(calculations, True/False): 0.39%\n",
      "multi(draw, True/False): 0.20%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:21.872474Z",
     "start_time": "2024-09-07T13:03:21.215648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpt4o=ChatOpenAI(\n",
    "    api_key=os.getenv(\"WLAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"WLAI_BASE_URL\"),\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "gpt4o.invoke(\"hello\")\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\")) # "
   ],
   "id": "ed9aa0c611d6cdc2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 翻译",
   "id": "574afcb7b791980c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:25.542697Z",
     "start_time": "2024-09-07T13:03:25.198690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tool.model import translate_prompt\n",
    "\n",
    "# 翻译所有问题，已经缓存，所以全量翻译\n",
    "translation_runnable= translate_prompt | gpt4o | StrOutputParser()\n",
    "translation_list = translation_runnable.batch([{\"text\":item[\"question\"]} for item in dataset], config={\"max_concurrency\":1}, return_exceptions=True)\n",
    "for i in range(0,len(dataset)):\n",
    "    dataset[i][\"translation\"]=translation_list[i]"
   ],
   "id": "645074f81eea53b7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 运行\n",
    "### 预处理\n",
    "1. 构建prompt\n",
    "2. 修改题目中文件名位置"
   ],
   "id": "785a6b9588f98da5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:30.131411Z",
     "start_time": "2024-09-07T13:03:30.114618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt4o import *\n",
    "for i in range(0, len(dataset)):\n",
    "    content = d_template[dataset[i][\"problem_type\"]].format(dataset[i][\"question\"])\n",
    "    filenames = extract_filenames(content)\n",
    "    for filename in filenames:\n",
    "        content = content.replace(filename, add_path(filename, data_path / 'Final_TestSet/data'))\n",
    "    dataset[i][\"content\"]=content"
   ],
   "id": "60042329e696a5cf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 问题改写\n",
    "1. 获取问题类型，构建list\n",
    "2. 根据每种类型，输出问题目标（问n次，再投票）\n",
    "3. 返回问题的list"
   ],
   "id": "ade469fcd36fab0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:03:37.921493Z",
     "start_time": "2024-09-07T13:03:33.965602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from tool.model import gpt4o\n",
    "\n",
    "\n",
    "def ask_llm_mutil_time(text:str, n=5,k=1):\n",
    "    texts=[str(i)+\"\\n\"+text for i in range(n)]\n",
    "    llm_outputs=(gpt4o|StrOutputParser()).batch(texts,config={\"max_concurrency\":k})\n",
    "    # print(\"llm_outputs\",llm_outputs)\n",
    "    prompt=f\"\"\"从下面的不同人表达中，直接返回大部分人想表达的内容，不附带其他信息：\\n\"\"\"+\"\\n\".join(llm_outputs)\n",
    "    return (gpt4o|StrOutputParser()).invoke(prompt)\n",
    "\n",
    "def get_goals(text:str, problem_type:str):\n",
    "    types=[]\n",
    "    goals=[]\n",
    "    if problem_type.startswith(\"multi\"):\n",
    "        types.extend(problem_type[6:-1].split(\", \"))\n",
    "    else:\n",
    "        types.append(problem_type)\n",
    "\n",
    "    for t in types:\n",
    "        if t==\"calculations\":\n",
    "            key_word=\"这通常是一个或多个图算法相关的指标\"\n",
    "        elif t==\"True/False\":\n",
    "            key_word=\"这通常是一个判断，返回True或False\"\n",
    "        elif t==\"draw\":\n",
    "            key_word=\"这通常是需要绘制一张图算法相关的图片\"\n",
    "        else:\n",
    "            raise Exception(\"unknown problem type\")\n",
    "    \n",
    "        prompt=f\"\"\"你是一个图算法专家，你需要从下面的任务描述中，提取出任务的最终目标，{key_word}。\\n<任务>\\n{text}\\n</任务>\\n。用第一人称，一句话转述这个任务的最终目标是什么。不要对最终目标进行任何计算，不需要考虑如何实现目标，以及条件\"\"\"\n",
    "        goal=ask_llm_mutil_time(prompt, n=15,k=5)\n",
    "        goals.append(goal)\n",
    "    \n",
    "    return goals\n",
    "        \n",
    "        \n",
    "        \n",
    "for i in tqdm(range(len(dataset))):\n",
    "    goals=get_goals(dataset[i][\"question\"], dataset[i][\"problem_type\"])\n",
    "    # print(i+1,goals)\n",
    "    dataset[i][\"goals\"]=goals\n",
    "    dataset[i][\"content\"]=dataset[i][\"content\"]+\"\\n\\n\"+\"\\n牢记任务目标：\\n\"+\"\\n\".join(goals)\n",
    "    "
   ],
   "id": "2dc0dfd1db5c315b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 12.70it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 运行agent",
   "id": "a0ca324b051de187"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from autogen import Cache\n",
    "\n",
    "def run(item: dict):\n",
    "    content = item[\"content\"]\n",
    "\n",
    "    # Use DiskCache as cache\n",
    "    with Cache.disk(cache_path_root=\"./autogen_cache\",cache_seed=1) as cache:\n",
    "        chat_result = code_executor_agent.initiate_chat(\n",
    "            code_writer_agent,\n",
    "            message=content,\n",
    "            summary_method='reflection_with_llm',\n",
    "            summary_args=dict(summary_prompt='only return the code output'),\n",
    "            cache=cache,\n",
    "            # silent=True,\n",
    "        )\n",
    "    # code = extract_python_code(chat_result.chat_history[-3]['content'])[-1]\n",
    "    code=\"\"\n",
    "    for i in range(len(chat_result.chat_history)-1, 0, -1):\n",
    "        l=extract_python_code(chat_result.chat_history[i]['content'])\n",
    "        if len(l)>0:\n",
    "            code=l[-1]\n",
    "            break\n",
    "    \n",
    "    answer = chat_result.summary\n",
    "    if isinstance(answer, dict):\n",
    "        answer = answer['content']\n",
    "    item[\"code\"]=code\n",
    "    item[\"answer\"]=answer\n",
    "    item['chat_history']=chat_result.chat_history\n",
    "    return item\n",
    "\n",
    "for item in tqdm(dataset[:]):\n",
    "    run(item)\n"
   ],
   "id": "372043cc6b22dc2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 存储",
   "id": "573bc4288f92333d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T13:18:16.458611Z",
     "start_time": "2024-09-07T13:18:16.434444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('data/SMP_240907_check_1.json', 'w', encoding='utf-8') as f:\n",
    "    s = json.dumps(dataset, indent=4, ensure_ascii=False)\n",
    "    f.write(s)"
   ],
   "id": "99d59b27c6efe78",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "----",
   "id": "28657a61d400979b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "raise Exception(\"stop\")",
   "id": "4f8860b7e6239bd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T08:08:22.362637Z",
     "start_time": "2024-09-06T08:08:22.316638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('data/SMP_240905_check_1.json', 'r', encoding='utf-8') as f:\n",
    "    tmp_dataset=json.load(f)"
   ],
   "id": "5148f3e17df16072",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tmp_id=50\n",
    "i=tmp_id-1\n",
    "print(tmp_dataset[i][\"ID\"], tmp_dataset[i][\"problem_type\"],\"\\n---\\n\", tmp_dataset[i][\"translation\"],\"\\n---\\n\", tmp_dataset[i]['answer'],\"\\n---\\n\",tmp_dataset[i][\"code\"],\"\\n---\\n\",tmp_dataset[i][\"question\"])"
   ],
   "id": "5dc053e492298f12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
